# Pet Image GAN
This project is a Generative Adversarial Network (GAN) designed to generate realistic fake pet images using the Oxford-IIIT Pet Dataset. The GAN consists of a generator model and a discriminator model trained together to generate high-quality pet images.


## Project Files
1. pet-image-GAN.ipynb: This Jupyter Notebook file contains the Python code for the GAN model and image generator.
2. pet_image_generator.h5: This file contains a pretrained generator model for generating pet images.
3. pet_image_discriminator.h5: This file contains a pretrained discriminator model for classifying real and fake pet images.
4. predictions folder: This folder is used to store the images generated by the model using the gan.predict() function.


## Download this dataset
The Oxford-IIIT Pet Dataset can be found [(here)](https://www.kaggle.com/datasets/tanlikesmath/the-oxfordiiit-pet-dataset).


## Software Requirements
This project is intended to work on Jupyter Notebook with Python 3.9+. To work with Jupyter Notebooks, please install Anaconda at the following link:
- [Anaconda](https://www.anaconda.com/download/)


## Python Package Depenencies
To run this Pet-Image-GAN project, please install the following dependencies:
- TensorFlow
- Keras
- OpenCV (cv2)
- Matplotlib
- NumPy
- scikit-learn

To install all of these dependencies in one command, you can use the following command. Make sure you install these with the proper permissions.
```
pip install tensorflow keras opencv-python matplotlib numpy scikit-learn
```


## Tested Platforms
This project is intended to work on any Operating System that supports Anaconda and Jupyter Notebook. However, this project has only been tested for a Windows 10+ environment


## Pet-Image-GAN Program Usage
1. Download the Oxford-IIIT Pet Dataset and place it in a folder called "images" at the root directory of the project.
2. Open the pet-image-GAN.ipynb file in Jupyter Notebook or any other compatible environment.
3. Set the desired model constants, such as IMAGE_SIZE, LATENT_DIMENSION, BATCH_SIZE, EPOCHS, and EVALS.
4. Modify the ImgLocation variable to specify the location of the downloaded pet images.
5. Specify the category variable to choose the type of pet image you want to generate (e.g., "Maine_Coon").
6. Run the notebook to train the GAN model and generate pet images.
7. The model will output the generator and discriminator losses at each epoch and evaluate the model's performance on the dataset.
8. Example pet images will be displayed and saved in the predictions folder.


### Using the Pretrained Models with Pet-Image-GAN
If you prefer to use the pretrained models instead of training the GAN from scratch, you can load the pet_image_generator.h5 and pet_image_discriminator.h5 files. Simply uncomment the lines in the notebook that load the pretrained models and comment out the lines related to model training.


## References
- https://www.geeksforgeeks.org/generative-adversarial-network-gan/
- https://www.educba.com/keras-batch-normalization/
- https://keras.io/api/layers/
- https://github.com/SolClover/Art053_NN_DCGAN


## License
This project is released under the MIT License.

Feel free to modify and adapt the code according to your needs.
